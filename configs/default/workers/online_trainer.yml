# Default name of section used for training.
# One can change this, but must remember to define all the required parameters in the new section.
training_section_name: training

# Default name of section used for validation.
# One can change this, but must remember to define all the required parameters in the new section.
validation_section_name: validation

# Default name of section containing pipeline definition.
# One can change this, but must remember to define all the required parameters in the new section.
pipeline_section_name: pipeline



# Section defining all the default values of parameters used during training.
training:
  # Set the random seeds: -1 means that they will be picked randomly.
  # Note: their final values will be stored in the final training_configuration.yml saved to log dir.
  seed_numpy: -1
  seed_torch: -1

  # Default batch size.
  batch_size: 64

  # Definition of the problem (Mandatory!)
  #problem:
  #  One must define its type (Mandatory!)
  #  type: ?
  #  The rest of the content of that section is problem-specific...
  
  # Section describing curriculum learning (Optional)
  #curriculum_learning: 
  #  # Flag indicating whether curriculum learning has to finish before (eventual) termination of the training.
  #  must_finish: True
  #  The rest of the content of that section is problem-specific...

  # Definition of optimizer (Mandatory!)
  #optimizer:
  #  # Type - generally all optimizers from PyTorch.optim are allowed (Mandatory!)
  #  type: Adam
  #  # Options: 
  #  lr: 0.0001
  #  The rest of the content of that section is optimizer-specific...

  # Set a default configuration section for data loader.
  dataloader:
    # Shuffle set by default.
    shuffle: True 
    batch_sampler: None
     # Do not use multiprocessing by default.
    num_workers: 0
    pin_memory: False
    # Do not drop last frame by default.
    drop_last: False
    timeout: 0

  # Definition of sampler (Optional)
  # When this section will not be present, worker will use "standard" sampling (please refer to shuffle in dataloader)
  #sampler:
  #  # Type - generally all samplers from PyTorch (plus some new onses) are allowed (Mandatory!)
  #  # Options: 
  #  type: RandomSmpler
  #  The rest of the content of that section is optimizer-specific...

  # Terminal conditions that will be used during training.
  # They can (and ofter should) be overwritten.
  terminal_conditions:
    # Terminal condition I: loss threshold, going below will terminate the training.
    loss_stop: 0.00001 # 1e-5
    # Terminal condition II: maximal number of epochs (optional, -1 means that this condition is disabled)
    epoch_limit: -1
    # Terminal condition III: maximal number of episodes (Mandatory for this trainer! Must be > 0)
    episode_limit: 100000


# Section defining all the default values of parameters used during training.
validation:
  # Defines how often the partial validation will be performed.
  # In this trainer Partial Validation is mandatory, hence interval must be > 0.
  partial_validation_interval: 100

  # Definition of the problem (mandatory!)
  #problem:
  #  One must define its type (Mandatory!)
  #  type: ?
  #  The rest of the content of that section is problem-specific...

  # Set a default configuration section for data loader.
  dataloader:
    # Shuffle set by default.
    shuffle: True 
     # Do not use multiprocessing by default.
    num_workers: 0
    pin_memory: False
    # Do not drop last frame by default.
    drop_last: False
    timeout: 0

  # Definition of sampler (Optional)
  # When this section will not be present, worker will use "standard" sampling (please refer to shuffle in dataloader)
  #sampler:
  #  # Type - generally all samplers from PyTorch (plus some new onses) are allowed (Mandatory!)
  #  # Options: 
  #  type: RandomSmpler
  #  The rest of the content of that section is optimizer-specific...

# Section defining the pipeline.
pipeline: 
  # Pipeline must contain at least one component.
  #name_1:
  #   Each component must have defined its priority... (Mandatory!)
  #   priority: 0.1 # Can be float. Smaller means higher priority, up to zero.
  #   # ... and type (Mandatory!)
  #   type: ?
  #   The rest of the content of that section is component-specific...


