# Load config defining problems for training, validation and testing.
default_configs: vqa_med_2019/c2_classification/default_c2_classification.yml

training:
  problem:
    batch_size: 32
    # Appy all preprocessing/data augmentations.
    image_preprocessing: normalize
    # none | random_affine | random_horizontal_flip | normalize | all
    question_preprocessing: lowercase,remove_punctuation,tokenize
    # none | lowercase | remove_punctuation | tokenize | random_remove_stop_words | random_shuffle_words | all
    streams: 
      # Problem is returning tokenized questions.
      questions: tokenized_questions

validation:
  problem:
    batch_size: 32
    question_preprocessing: lowercase,remove_punctuation,tokenize
    # none | lowercase | remove_punctuation | tokenize | random_remove_stop_words | random_shuffle_words | all
    streams: 
      # Problem is returning tokenized questions.
      questions: tokenized_questions


pipeline:
  name: c2_class_lstm_resnet152_rn_cat_is

  global_publisher:
    priority: 0
    type: GlobalVariablePublisher
    # Add input_size to globals.
    keys: [question_encoder_output_size,rn_activation_size,image_size_encoder_input_size, image_size_encoder_output_size]
    values: [100, 100, 2, 10]

  ################# PIPE 0: question #################

  # Model 1: Embeddings
  question_embeddings:
    priority: 1.2
    type: SentenceEmbeddings
    embeddings_size: 100
    pretrained_embeddings_file: glove.6B.100d.txt
    data_folder: ~/data/vqa-med
    word_mappings_file: questions.all.word.mappings.csv
    streams:
      inputs: tokenized_questions
      outputs: embedded_questions      
  
  # Model 2: RNN
  question_lstm:
    priority: 1.3
    type: RecurrentNeuralNetwork
    cell_type: LSTM
    prediction_mode: Last
    use_logsoftmax: False
    initial_state: Trainable
    dropout_rate: 0.1
    hidden_size: 50
    streams:
      inputs: embedded_questions
      predictions: question_activations
    globals:
      input_size: embeddings_size
      prediction_size: question_encoder_output_size

  ################# PIPE 2: image #################
  # Image encoder.
  image_encoder:
    priority: 3.1
    type: TorchVisionWrapper
    model_type: resnet152
    return_feature_maps: True
    streams:
      inputs: images
      outputs: feature_maps

  ################# PIPE 3: Fusion: Relational Network #################
  # Object-object relations.
  question_image_fusion:
    priority: 4.1
    type: RelationalNetwork
    dropout_rate: 0.5
    g_theta_sizes: [512, 256]
    streams:
      question_encodings: question_activations
      outputs: fused_image_question_activations
    globals:
      question_encoding_size: question_encoder_output_size
      output_size: fused_image_question_activation_size

  question_image_ffn:
    priority: 4.2
    type: FeedForwardNetwork 
    hidden_sizes: [128,100]
    dropout_rate: 0.5
    streams:
      inputs: fused_image_question_activations
      predictions: rn_activation
    globals:
      input_size: fused_image_question_activation_size
      prediction_size: rn_activation_size


  ################# PIPE 5: image-question-image size fusion + classification #################
  # Model - image size FFN.
  image_size_encoder:
    priority: 5.1
    type: FeedForwardNetwork 
    streams:
      inputs: image_sizes
      predictions: image_size_activations
    globals:
      input_size: image_size_encoder_input_size
      prediction_size: image_size_encoder_output_size

  # 6th subpipeline: concatenation + FF.
  concat:
    priority: 5.2
    type: Concatenation
    input_streams: [rn_activation,image_size_activations]
    # Concatenation 
    dim: 1 # default
    input_dims: [[-1,100],[-1,10]]
    output_dims: [-1,110]
    streams:
      outputs: concatenated_activations
    globals:
      output_size: concatentated_activations_size

  classifier:
    priority: 5.3
    type: FeedForwardNetwork 
    hidden_sizes: [100]
    dropout_rate: 0.5
    streams:
      inputs: concatenated_activations
    globals:
      input_size: concatentated_activations_size
      prediction_size: vocabulary_size_c2

  #: pipeline
